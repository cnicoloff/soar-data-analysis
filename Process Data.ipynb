{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autoreload reloads modules automatically before entering the execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "\n",
    "# Show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import halfnorm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Formatting Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "plt.rcParams['axes.titlesize'] = 28\n",
    "plt.rcParams['axes.labelsize'] = 24\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ten minutes with a Cs-137 source\n",
    "#data_dir = r\".\\2018-05-03\"\n",
    "#data_file = \"%s\\counts_cesium_ten_minutes.txt\" % (data_dir)\n",
    "\n",
    "# Data from the tethered launch\n",
    "#data_dir = r\".\\2018-05-08\"\n",
    "#data_file = \"%s\\counts_tethered_launch.txt\" % (data_dir)\n",
    "\n",
    "# Data from the launch!\n",
    "data_dir = r\".\\2018-05-13\"\n",
    "counts_file = \"%s/counts_launch.txt\" % (data_dir)\n",
    "star_file = \"%s/counts_launch.csv\" % (data_dir)\n",
    "tel_file = \"%s/telemetrydata.txt\" % (data_dir)\n",
    "gps_file = \"%s/pits_gps.txt\" % (data_dir)\n",
    "pits_file = \"%s/pits_images.txt\" % (data_dir)\n",
    "msi_file = \"%s/msi_images.txt\" % (data_dir)\n",
    "\n",
    "msi_seeds = np.array([int(391900854), int(18925409), int(315370512)])\n",
    "\n",
    "joined_file = \"%s/data_joined.csv\" % (data_dir)\n",
    "\n",
    "pat = \"^\\$\\$KC1FNU,\\d*,(\\d+)\\:(\\d+)\\:(\\d+),([0-9.]*),-([0-9.]*),(\\d*),[0-9,.-]*\\*([0-9A-F]*)$\"\n",
    "pat1 = \"^\\$GNGGA,(\\d{2})(\\d{2})(\\d{2}).\\d{2},(\\d{2})([0-9.]{1,}),N,(\\d{3})([0-9.]{1,}),W,\\d{1,},\\d{1,},[0-9.]{1,},([0-9.]{1,}),M,[0-9.-]{1,},M,.*?$\"\n",
    "pat2 = \"^.*?\\s{1,}((\\d{2})_(\\d{2})_(\\d{2})-rot.jpg)\\s*$\"\n",
    "pat3 = \"^.*?\\s{1,}(\\d{4}-\\d{2}-\\d{2}_(\\d{2})(\\d{2})(\\d{2})-(\\d{1,})-cam(\\d{1}).jpg)\\s*$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See if a value is a number or not\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Convert a number to float or int\n",
    "def cvt_number(s):\n",
    "    if ('.' in s):\n",
    "        num = float(s)\n",
    "    else:\n",
    "        num = int(s)\n",
    "    return num\n",
    "\n",
    "# Round a number to a certain number of decimal places\n",
    "def round_precision(num, precision):\n",
    "    p10 = 10**precision\n",
    "    num = num * p10\n",
    "    num = np.ceil(num)\n",
    "    num = num / p10\n",
    "    return num\n",
    "\n",
    "# Calculate a running mean/moving average\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "# Calculate the average deadtime per interval\n",
    "def avg_deadtime(dead_time, deadt_counts):\n",
    "    # Divide in such a way that division by zero doesn't halt the program\n",
    "    # Instead, it returns a zero\n",
    "    avg_deadt = np.divide(dead_time, deadt_counts, out=np.zeros_like(dead_time), where=deadt_counts!=0)\n",
    "    return avg_deadt\n",
    "\n",
    "# When HV isn't on, the counts are -1, so trim those entries\n",
    "def enforce_min_counts(seconds, counts, dead_time, deadt_counts, T_raw, T, P_raw, P1, P2, alt, min_counts):\n",
    "    seconds = np.array(seconds[np.where(deadt_counts >= min_counts)])\n",
    "    counts = np.array(counts[np.where(deadt_counts >= min_counts)])\n",
    "    T_raw = np.array(T_raw[np.where(deadt_counts >= min_counts)])\n",
    "    T = np.array(T[np.where(deadt_counts >= min_counts)])\n",
    "    P_raw = np.array(P_raw[np.where(deadt_counts >= min_counts)])\n",
    "    P1 = np.array(P1[np.where(deadt_counts >= min_counts)], dtype='float64')\n",
    "    P2 = np.array(P2[np.where(deadt_counts >= min_counts)], dtype='float64')\n",
    "    alt = np.array(alt[np.where(deadt_counts >= min_counts)])\n",
    "    dead_time = np.array(dead_time[np.where(deadt_counts >= min_counts)])\n",
    "    deadt_counts = np.array(deadt_counts[np.where(deadt_counts >= min_counts)])\n",
    "    seconds_dt = np.gradient(seconds)\n",
    "    \n",
    "    return seconds, seconds_dt, counts, dead_time, deadt_counts, T_raw, T, P_raw, P1, P2, alt\n",
    "\n",
    "# Find all indices that have a minimum number of counts\n",
    "def loc_min_counts(counts, min_counts):\n",
    "    return np.where(counts >= min_counts)\n",
    "\n",
    "# Corrects counts for dead time, avg_deadt can be a scalar or a per-interval array\n",
    "def deadt_correction(seconds_dt, deadt_counts, avg_deadt):\n",
    "    counts_c = deadt_counts / (1 - (deadt_counts/seconds_dt) * avg_deadt)\n",
    "    return counts_c\n",
    "\n",
    "def altitude_logarithmic(P, T, QFF):\n",
    "    # ftp://ftp.nist.gov/pub/physics/lunarproject/References/Atmospheric_Properties/Pressure%20to%20Altitude%20Conversion%20%232.pdf\n",
    "    P_0 = np.array(np.ones_like(P) * QFF, dtype='float64')\n",
    "    T_0 = 288.150\n",
    "    alt = (10**(np.log10(P/P_0)/5.2558797)- 1)/(-6.8755856*10**(-6))\n",
    "    alt = alt * (T[0]+273.15)/T_0\n",
    "    alt = alt * 0.3048  # Convert to meters\n",
    "    return alt\n",
    "\n",
    "def altitude_hypsometric(T, P):\n",
    "    N = 2\n",
    "    R = 287.058\n",
    "    g = 9.80665\n",
    "    \n",
    "    dz = np.zeros_like(T)\n",
    "    \n",
    "    for i in range(1, len(T)):\n",
    "        T_ave = ((T[i] + T[i-1]) / 2.0) + 273.15\n",
    "        P1 = P[i-1]\n",
    "        P2 = P[i]\n",
    "        \n",
    "        dz[i] = (R * T_ave / g) * np.log(P1/P2)\n",
    "    \n",
    "    alt = np.cumsum(dz)\n",
    "    \n",
    "    return alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.isfile(star_file):\n",
    "        df_star = pd.read_csv(star_file, index_col='Elapsed')\n",
    "        \n",
    "except:\n",
    "    # The CSV file has a header row\n",
    "    header = True\n",
    "\n",
    "    # Read the CSV file into a Pandas DataFrame\n",
    "    with open(counts_file, 'rb') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        for row in csvreader:\n",
    "            if (header):\n",
    "                indexName  = row[0]   # assume that first column label is the index\n",
    "                df_columns = row[1:]  # second through final header become DataFrame column names\n",
    "                df_star = pd.DataFrame(columns=df_columns)\n",
    "                header = False\n",
    "                next\n",
    "            else:\n",
    "                for ii in range(len(row)):\n",
    "                    if is_number(row[ii]):\n",
    "                        row[ii] = cvt_number(row[ii])\n",
    "                    df_star = df_star.append(pd.DataFrame([row[1:]], columns=df_columns, index=[row[0]]), ignore_index=False)\n",
    "\n",
    "    df_star.to_csv(star_file, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if os.path.isfile(tel_file):\n",
    "        with open(tel_file, 'r') as telfile:\n",
    "            indexName = ['Elapsed']\n",
    "            df_columns = ['Timestamp', 'Lat', 'Long', 'Elev']\n",
    "            df_tel = pd.DataFrame(columns=df_columns)\n",
    "            for row in telfile:\n",
    "                try:\n",
    "                    m = re.match(pat, row)\n",
    "                    if (m):\n",
    "                        dt = datetime.datetime(2018, 5, 13, (int(m.group(1))-4), int(m.group(2)), int(m.group(3)))\n",
    "                        hh = int(m.group(1)) - 17  # Telemetry was in Zulu time\n",
    "                        mm = int(m.group(2)) - 39  # To sync with beginning of MSI data\n",
    "                        ss = int(m.group(3)) - 34  # To sync with beginning of MSI data\n",
    "                        elapsed_time = hh * 3600 + mm * 60 + ss\n",
    "                        df_tel = df_tel.append(pd.DataFrame([[dt, float(m.group(4)), -1*float(m.group(5)), float(m.group(6))]], columns=df_columns, index=[elapsed_time]), ignore_index=False)\n",
    "                    else:\n",
    "                        print row\n",
    "                except:\n",
    "                    print \"Exception.\"\n",
    "    else:\n",
    "        print \"File not found!\"\n",
    "except:\n",
    "    print \"File IO error.\"\n",
    "    \n",
    "df_tel = df_tel[~df_tel.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion from Degrees Minutes.m to Decimal Degrees\n",
    "# https://www.directionsmag.com/site/latlong-converter/\n",
    "\n",
    "try:\n",
    "    if os.path.isfile(gps_file):\n",
    "        with open(gps_file, 'r') as gpsfile:\n",
    "            indexName = ['Elapsed']\n",
    "            df_columns = ['Datetime', 'Lat', 'Long', 'Elev']\n",
    "            df_gps = pd.DataFrame(columns=df_columns)\n",
    "            for row in gpsfile:\n",
    "                try:\n",
    "                    m = re.match(pat1, row)\n",
    "                    if (m):\n",
    "                        #print m.group(4), m.group(5), m.group(6), m.group(7)\n",
    "                        if ((int(m.group(1)) >= 17) and (int(m.group(1)) <= 23)):\n",
    "                            dt = datetime.datetime(2018, 5, 13, (int(m.group(1))-4), int(m.group(2)), int(m.group(3)))\n",
    "                            hh = int(m.group(1)) - 17  # Telemetry was in Zulu time\n",
    "                            mm = int(m.group(2)) - 39  # To sync with beginning of MSI data\n",
    "                            ss = int(m.group(3)) - 34  # To sync with beginning of MSI data\n",
    "                            elapsed_time = hh * 3600 + mm * 60 + ss\n",
    "                            lat = int(m.group(4)) + float(m.group(5)) / 60.0\n",
    "                            lon = -1 * (int(m.group(6)) + float(m.group(7)) / 60.0)\n",
    "                            elev = float(m.group(8))\n",
    "                            #print elapsed_time, lat, lon, elev\n",
    "                            df_gps = df_gps.append(pd.DataFrame([[dt, lat, lon, elev]], columns=df_columns, index=[elapsed_time]), ignore_index=False)\n",
    "                    else:\n",
    "                        next\n",
    "                        #print row\n",
    "                except:\n",
    "                    print \"Exception.\"\n",
    "    else:\n",
    "        print \"File not found!\"\n",
    "except:\n",
    "    print \"File IO error.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "    Directory: C:\\Users\\c_nic\\Documents\\ASTR 202\\pits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mode                LastWriteTime         Length Name                                                                  \n",
      "\n",
      "----                -------------         ------ ----                                                                  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if os.path.isfile(pits_file):\n",
    "        with open(pits_file, 'r') as pitsfile:\n",
    "            indexName = ['Elapsed']\n",
    "            df_columns = ['PITS Image']\n",
    "            df_pits = pd.DataFrame(columns=df_columns)\n",
    "            for row in pitsfile:\n",
    "                try:\n",
    "                    m = re.match(pat2, row)\n",
    "                    if (m):\n",
    "                        hh = int(m.group(2)) - 13 # To sync with beginning of MSI data\n",
    "                        mm = int(m.group(3)) - 39 # To sync with beginning of MSI data\n",
    "                        ss = int(m.group(4)) - 34 # To sync with beginning of MSI data\n",
    "                        elapsed_time = hh * 3600 + mm * 60 + ss\n",
    "                        df_pits = df_pits.append(pd.DataFrame([m.group(1)], columns=df_columns, index=[elapsed_time]), ignore_index=False)\n",
    "                    else:\n",
    "                        print row\n",
    "                except:\n",
    "                    next\n",
    "    else:\n",
    "        print \"File not found!\"\n",
    "except:\n",
    "    print \"File IO error.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "    Directory: C:\\Users\\c_nic\\Documents\\ASTR 202\\msi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mode                LastWriteTime         Length Name                                                                  \n",
      "\n",
      "----                -------------         ------ ----                                                                  \n",
      "\n",
      "No seed found.\n",
      "0\n",
      "0\n",
      "60\n",
      "60\n",
      "120\n",
      "120\n",
      "180\n",
      "180\n",
      "240\n",
      "240\n",
      "300\n",
      "300\n",
      "360\n",
      "360\n",
      "420\n",
      "420\n",
      "480\n",
      "480\n",
      "540\n",
      "540\n",
      "600\n",
      "600\n",
      "660\n",
      "660\n",
      "720\n",
      "720\n",
      "780\n",
      "780\n",
      "840\n",
      "840\n",
      "900\n",
      "900\n",
      "960\n",
      "960\n",
      "1020\n",
      "1020\n",
      "1080\n",
      "1080\n",
      "1140\n",
      "1140\n",
      "1200\n",
      "1200\n",
      "1260\n",
      "1260\n",
      "1320\n",
      "1320\n",
      "1380\n",
      "1380\n",
      "1440\n",
      "1440\n",
      "1500\n",
      "1500\n",
      "1560\n",
      "1560\n",
      "1620\n",
      "1620\n",
      "1680\n",
      "1680\n",
      "1740\n",
      "1740\n",
      "1800\n",
      "1800\n",
      "1860\n",
      "1860\n",
      "1920\n",
      "1920\n",
      "1980\n",
      "1980\n",
      "2040\n",
      "2040\n",
      "2100\n",
      "2100\n",
      "2160\n",
      "2160\n",
      "2220\n",
      "2220\n",
      "2280\n",
      "2280\n",
      "2340\n",
      "2340\n",
      "2400\n",
      "2400\n",
      "2460\n",
      "2460\n",
      "2520\n",
      "2520\n",
      "2580\n",
      "2580\n",
      "2640\n",
      "2640\n",
      "2700\n",
      "2700\n",
      "2760\n",
      "2760\n",
      "2820\n",
      "2820\n",
      "2880\n",
      "2880\n",
      "2940\n",
      "2940\n",
      "3000\n",
      "3000\n",
      "3060\n",
      "3060\n",
      "3120\n",
      "3120\n",
      "3180\n",
      "3180\n",
      "3240\n",
      "3240\n",
      "3300\n",
      "3300\n",
      "3360\n",
      "3360\n",
      "3420\n",
      "3420\n",
      "3480\n",
      "3480\n",
      "3540\n",
      "3540\n",
      "3601\n",
      "3601\n",
      "3661\n",
      "3661\n",
      "3721\n",
      "3721\n",
      "3781\n",
      "3781\n",
      "3841\n",
      "3841\n",
      "3901\n",
      "3901\n",
      "3961\n",
      "3961\n",
      "4021\n",
      "4021\n",
      "4081\n",
      "4081\n",
      "4141\n",
      "4141\n",
      "4201\n",
      "4201\n",
      "4261\n",
      "4261\n",
      "4321\n",
      "4321\n",
      "4381\n",
      "4381\n",
      "4441\n",
      "4441\n",
      "4501\n",
      "4501\n",
      "4561\n",
      "4561\n",
      "4621\n",
      "4621\n",
      "4681\n",
      "4681\n",
      "4741\n",
      "4741\n",
      "4801\n",
      "4801\n",
      "4861\n",
      "4861\n",
      "4921\n",
      "4921\n",
      "4981\n",
      "4981\n",
      "5041\n",
      "5041\n",
      "5101\n",
      "5101\n",
      "5161\n",
      "5161\n",
      "5221\n",
      "5221\n",
      "5281\n",
      "5286\n",
      "5286\n",
      "8098\n",
      "8098\n",
      "5346\n",
      "5346\n",
      "8158\n",
      "8158\n",
      "5406\n",
      "5406\n",
      "8218\n",
      "8218\n",
      "5466\n",
      "5466\n",
      "8278\n",
      "8278\n",
      "5526\n",
      "5526\n",
      "8338\n",
      "8338\n",
      "5586\n",
      "5586\n",
      "8398\n",
      "8398\n",
      "5646\n",
      "5646\n",
      "8458\n",
      "8458\n",
      "5706\n",
      "5706\n",
      "8518\n",
      "8518\n",
      "5766\n",
      "5766\n",
      "8578\n",
      "8578\n",
      "5826\n",
      "5826\n",
      "8638\n",
      "8638\n",
      "5886\n",
      "5886\n",
      "8698\n",
      "8698\n",
      "5946\n",
      "5946\n",
      "8758\n",
      "8758\n",
      "6006\n",
      "6006\n",
      "8818\n",
      "8818\n",
      "6066\n",
      "6066\n",
      "8878\n",
      "8878\n",
      "6126\n",
      "6126\n",
      "8938\n",
      "8938\n",
      "6186\n",
      "6186\n",
      "8998\n",
      "8998\n",
      "6246\n",
      "6246\n",
      "9058\n",
      "9058\n",
      "6306\n",
      "6306\n",
      "9118\n",
      "9118\n",
      "6366\n",
      "6366\n",
      "9178\n",
      "9178\n",
      "6426\n",
      "6426\n",
      "9238\n",
      "9238\n",
      "6486\n",
      "6486\n",
      "9298\n",
      "9298\n",
      "6546\n",
      "6546\n",
      "9358\n",
      "9358\n",
      "6606\n",
      "6606\n",
      "9418\n",
      "9418\n",
      "6666\n",
      "6666\n",
      "9478\n",
      "9478\n",
      "6726\n",
      "6726\n",
      "9538\n",
      "9538\n",
      "6786\n",
      "6786\n",
      "9598\n",
      "9598\n",
      "6846\n",
      "6846\n",
      "9658\n",
      "9658\n",
      "6906\n",
      "6906\n",
      "9718\n",
      "9718\n",
      "6966\n",
      "6966\n",
      "9778\n",
      "9778\n",
      "7026\n",
      "7026\n",
      "9838\n",
      "9838\n",
      "7086\n",
      "7086\n",
      "9898\n",
      "9898\n",
      "7146\n",
      "7146\n",
      "9958\n",
      "9958\n",
      "7206\n",
      "7206\n",
      "10018\n",
      "10018\n",
      "7266\n",
      "7266\n",
      "10078\n",
      "10078\n",
      "7326\n",
      "7326\n",
      "10138\n",
      "10138\n",
      "7386\n",
      "7386\n",
      "10198\n",
      "10198\n",
      "7446\n",
      "7446\n",
      "10258\n",
      "10258\n",
      "7506\n",
      "7506\n",
      "10318\n",
      "10318\n",
      "7566\n",
      "7566\n",
      "10378\n",
      "10378\n",
      "7626\n",
      "7626\n",
      "10438\n",
      "10438\n",
      "7686\n",
      "7686\n",
      "10498\n",
      "10498\n",
      "7746\n",
      "7746\n",
      "10558\n",
      "10558\n",
      "7806\n",
      "7806\n",
      "10618\n",
      "10618\n",
      "7866\n",
      "7866\n",
      "10678\n",
      "10678\n",
      "7926\n",
      "7926\n",
      "10738\n",
      "10738\n",
      "7986\n",
      "7986\n",
      "10798\n",
      "10798\n",
      "8046\n",
      "8046\n",
      "10858\n",
      "10858\n",
      "10918\n",
      "10918\n",
      "10978\n",
      "10978\n",
      "11038\n",
      "11038\n",
      "11098\n",
      "11098\n",
      "11158\n",
      "11158\n",
      "11218\n",
      "11218\n",
      "11278\n",
      "11278\n",
      "11338\n",
      "11338\n",
      "11398\n",
      "11398\n",
      "11458\n",
      "11458\n",
      "11519\n",
      "11519\n",
      "11579\n",
      "11579\n",
      "11639\n",
      "11639\n",
      "11699\n",
      "11699\n",
      "11759\n",
      "11759\n",
      "11819\n",
      "11819\n",
      "11879\n",
      "11879\n",
      "11939\n",
      "11939\n",
      "11999\n",
      "11999\n",
      "12059\n",
      "12059\n",
      "12119\n",
      "12119\n",
      "12179\n",
      "12179\n",
      "12239\n",
      "12239\n",
      "12299\n",
      "12299\n",
      "12359\n",
      "12359\n",
      "12419\n",
      "12419\n",
      "12479\n",
      "12479\n",
      "12539\n",
      "12539\n",
      "12599\n",
      "12599\n",
      "12659\n",
      "12659\n",
      "12719\n",
      "12719\n",
      "12779\n",
      "12779\n",
      "12839\n",
      "12839\n",
      "12899\n",
      "12899\n",
      "12959\n",
      "12959\n",
      "13019\n",
      "13019\n",
      "13079\n",
      "13079\n",
      "13139\n",
      "13139\n",
      "13199\n",
      "13199\n",
      "13259\n",
      "13259\n",
      "13319\n",
      "13319\n",
      "13379\n",
      "13379\n",
      "13439\n",
      "13439\n",
      "13499\n",
      "13499\n",
      "13559\n",
      "13559\n",
      "13619\n",
      "13619\n",
      "13679\n",
      "13679\n",
      "13739\n",
      "13739\n",
      "13799\n",
      "13799\n",
      "13859\n",
      "13859\n",
      "13919\n",
      "13919\n",
      "13979\n",
      "13979\n",
      "14039\n",
      "14039\n",
      "14099\n",
      "14099\n",
      "14159\n",
      "14159\n",
      "14219\n",
      "14219\n",
      "14279\n",
      "14279\n",
      "14339\n",
      "14339\n",
      "14399\n",
      "14399\n",
      "14459\n",
      "14459\n",
      "14519\n",
      "14519\n",
      "14579\n",
      "14579\n",
      "14639\n",
      "14639\n",
      "14699\n",
      "14699\n",
      "14759\n",
      "14759\n",
      "14819\n",
      "14819\n",
      "14879\n",
      "14879\n",
      "14939\n",
      "14939\n",
      "14999\n",
      "14999\n",
      "15059\n",
      "15059\n",
      "15119\n",
      "15119\n",
      "15179\n",
      "15179\n",
      "15239\n",
      "15239\n",
      "15299\n",
      "15299\n",
      "15359\n",
      "15359\n",
      "15419\n",
      "15419\n",
      "15479\n",
      "15479\n",
      "15539\n",
      "15539\n",
      "15599\n",
      "15599\n",
      "15659\n",
      "15659\n",
      "15719\n",
      "15719\n",
      "15779\n",
      "15779\n",
      "15840\n",
      "15840\n",
      "15900\n",
      "15900\n",
      "15960\n",
      "15960\n",
      "16020\n",
      "16020\n",
      "16080\n",
      "16080\n",
      "16140\n",
      "16140\n",
      "16200\n",
      "16200\n",
      "16260\n",
      "16260\n",
      "16320\n",
      "16320\n",
      "16380\n",
      "16380\n",
      "16440\n",
      "16440\n",
      "16500\n",
      "16500\n",
      "16560\n",
      "16560\n",
      "16620\n",
      "16620\n",
      "16680\n",
      "16680\n",
      "16740\n",
      "16740\n",
      "16800\n",
      "16800\n",
      "16860\n",
      "16860\n",
      "16920\n",
      "16920\n",
      "16980\n",
      "16980\n",
      "17040\n",
      "17040\n",
      "17100\n",
      "17100\n",
      "17160\n",
      "17160\n",
      "17220\n",
      "17220\n",
      "17280\n",
      "17280\n",
      "17340\n",
      "17340\n",
      "17400\n",
      "17400\n",
      "17460\n",
      "17460\n",
      "17520\n",
      "17520\n",
      "17580\n",
      "17580\n",
      "17640\n",
      "17640\n",
      "17700\n",
      "17700\n",
      "17760\n",
      "17760\n",
      "17820\n",
      "17820\n",
      "17880\n",
      "17880\n",
      "17940\n",
      "17940\n",
      "18000\n",
      "18000\n",
      "18060\n",
      "18060\n",
      "18120\n",
      "18120\n",
      "18180\n",
      "18180\n",
      "18240\n",
      "18240\n",
      "18300\n",
      "18300\n",
      "18360\n",
      "18360\n",
      "18420\n",
      "18420\n",
      "18480\n",
      "18480\n",
      "18540\n",
      "18540\n",
      "18600\n",
      "18600\n",
      "18660\n",
      "18660\n",
      "18720\n",
      "18720\n",
      "18780\n",
      "18780\n",
      "18840\n",
      "18840\n",
      "18900\n",
      "18900\n",
      "18960\n",
      "18960\n",
      "19020\n",
      "19020\n",
      "19080\n",
      "19080\n",
      "19140\n",
      "19140\n",
      "19200\n",
      "19200\n",
      "19260\n",
      "19260\n",
      "19320\n",
      "19320\n",
      "19380\n",
      "19380\n",
      "19440\n",
      "19440\n",
      "19500\n",
      "19500\n",
      "19560\n",
      "19560\n",
      "19620\n",
      "19620\n",
      "19680\n",
      "19680\n",
      "19740\n",
      "19740\n",
      "19800\n",
      "19800\n",
      "19860\n",
      "19860\n",
      "19920\n",
      "19920\n",
      "19980\n",
      "19980\n",
      "20040\n",
      "20040\n",
      "20101\n",
      "20101\n",
      "20161\n",
      "20161\n",
      "20221\n",
      "20221\n",
      "20281\n",
      "20281\n",
      "20341\n",
      "20341\n",
      "20401\n",
      "20401\n",
      "20461\n",
      "20461\n",
      "20521\n",
      "20521\n",
      "20581\n",
      "20581\n",
      "20641\n",
      "20641\n",
      "20701\n",
      "20701\n",
      "20761\n",
      "20761\n",
      "20821\n",
      "20821\n",
      "20881\n",
      "20881\n",
      "20941\n",
      "20941\n",
      "21001\n",
      "21001\n",
      "21061\n",
      "21061\n",
      "21121\n",
      "21121\n",
      "21181\n",
      "21181\n",
      "21241\n",
      "21241\n",
      "21301\n",
      "21301\n",
      "21361\n",
      "21361\n",
      "21421\n",
      "21421\n",
      "21481\n",
      "21481\n",
      "21541\n",
      "21541\n",
      "21601\n",
      "21601\n",
      "21661\n",
      "21661\n",
      "21721\n",
      "21721\n",
      "21781\n",
      "21781\n",
      "21841\n",
      "21841\n",
      "21901\n",
      "21901\n",
      "21961\n",
      "21961\n",
      "22021\n",
      "22021\n",
      "22081\n",
      "22081\n",
      "22141\n",
      "22141\n",
      "22201\n",
      "22201\n",
      "22261\n",
      "22261\n",
      "22321\n",
      "22321\n",
      "22381\n",
      "22381\n",
      "22441\n",
      "22441\n",
      "22501\n",
      "22501\n",
      "22561\n",
      "22561\n",
      "22621\n",
      "22621\n",
      "22681\n",
      "22681\n",
      "22741\n",
      "22741\n",
      "22801\n",
      "22801\n",
      "22861\n",
      "22861\n",
      "22921\n",
      "22921\n",
      "22981\n",
      "22981\n",
      "23041\n",
      "23041\n",
      "23101\n",
      "23101\n",
      "23161\n",
      "23161\n",
      "23221\n",
      "23221\n",
      "23281\n",
      "23281\n",
      "23341\n",
      "23341\n",
      "23401\n",
      "23401\n",
      "23461\n",
      "23461\n",
      "23521\n",
      "23521\n",
      "23581\n",
      "23581\n",
      "23641\n",
      "23641\n",
      "23701\n",
      "23701\n",
      "23761\n",
      "23761\n",
      "23821\n",
      "23821\n",
      "23881\n",
      "23881\n",
      "23941\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if os.path.isfile(msi_file):\n",
    "        with open(msi_file, 'r') as msifile:\n",
    "            indexName = ['Elapsed']\n",
    "            df_columns = ['MSI Image', 'MSI IR Image']\n",
    "            df_msi = pd.DataFrame(columns=df_columns)\n",
    "            for row in msifile:\n",
    "                try:\n",
    "                    m = re.match(pat3, row)\n",
    "                    if (m):\n",
    "                        cam0 = m.group(1).replace(\"cam1\", \"cam0\")\n",
    "                        cam1 = m.group(1).replace(\"cam0\", \"cam1\")\n",
    "                        \n",
    "                        seed = int(m.group(5))\n",
    "                        \n",
    "                        try:\n",
    "                            which_seed = int(np.where(msi_seeds == seed)[0][0])\n",
    "\n",
    "                            if (which_seed == 0):\n",
    "                                #print m.group(2), m.group(3), m.group(4)\n",
    "                                hh = int(m.group(2)) - 13\n",
    "                                mm = int(m.group(3)) - 39\n",
    "                                ss = int(m.group(4)) - 34\n",
    "                                elapsed_time = hh * 3600 + mm * 60 + ss\n",
    "                                \n",
    "                                df_msi = df_msi.append(pd.DataFrame([[cam0, cam1]], columns=df_columns, index=[elapsed_time]), ignore_index=False)\n",
    "                            elif (which_seed == 1):\n",
    "                                # Use syslog to figure out how long the boot process took\n",
    "                                # Reboot happened at 15:06:37 and lasted 4.5s\n",
    "                                # Time was reset to 12:00:00\n",
    "\n",
    "                                #print m.group(2), m.group(3), m.group(4)\n",
    "                                hh = int(m.group(2)) - 12 + 1\n",
    "                                mm = int(m.group(3)) - 0 + 27\n",
    "                                ss = int(m.group(4)) - 1 + 3 + 4\n",
    "                                elapsed_time = hh * 3600 + mm * 60 + ss\n",
    "                                #print elapsed_time\n",
    "                                df_msi = df_msi.append(pd.DataFrame([[cam0, cam1]], columns=df_columns, index=[elapsed_time]), ignore_index=False)\n",
    "                            elif (which_seed == 2):\n",
    "                                # Use syslog to figure out how long the boot process took\n",
    "                                # Reboot happened at 12:46:48 and lasted 3.3s\n",
    "                                # Time was reset to 12:00:00\n",
    "                                #print m.group(2), m.group(3), m.group(4)\n",
    "\n",
    "                                hh = int(m.group(2)) - 12 + 2\n",
    "                                mm = int(m.group(3)) - 0 + 13\n",
    "                                ss = int(m.group(4)) - 1 + 7 + 48 + 4\n",
    "                                elapsed_time = hh * 3600 + mm * 60 + ss\n",
    "                                #print elapsed_time\n",
    "                                df_msi = df_msi.append(pd.DataFrame([[cam0, cam1]], columns=df_columns, index=[elapsed_time]), ignore_index=False)\n",
    "                            else:\n",
    "                                print m.group(1)\n",
    "                            #print elapsed_time\n",
    "                        except:\n",
    "                            print \"No seed found.\"\n",
    "                    else:\n",
    "                        print row\n",
    "                except:\n",
    "                    next\n",
    "    else:\n",
    "        print \"File not found!\"\n",
    "except:\n",
    "    print \"File IO error.\"\n",
    "    \n",
    "#msi_df = msi_df.sort_index()\n",
    "df_msi = df_msi[~df_msi.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Counts   T (Raw)     T1 (C)   P (Raw)    P1 (mbar)    P2 (mbar)  \\\n",
      "Elapsed                                                                        \n",
      "792305.504       -1   8424522  29.624726   6760918  1009.786643  1009.786643   \n",
      "792306.504       -1   8424604  29.627446   6760768  1009.733632  1009.733632   \n",
      "792307.504       -1   8424642  29.628707   6760756  1009.731755  1009.731755   \n",
      "792308.504       -1   8424664  29.629437   6760868  1009.777593  1009.777593   \n",
      "\n",
      "             Altitude (m)   Dead Time (s)   Dead Time Counts  \n",
      "Elapsed                                                       \n",
      "792305.504      97.012924             0.0                 -1  \n",
      "792306.504      97.467407             0.0                 -1  \n",
      "792307.504      97.483696             0.0                 -1  \n",
      "792308.504      97.091202             0.0                 -1  \n",
      "             Timestamp       Lat      Long   Elev\n",
      "29 2018-05-13 13:40:03  43.08361 -73.76945  105.0\n",
      "30 2018-05-13 13:40:04  43.08361 -73.76946  105.0\n",
      "35 2018-05-13 13:40:09  43.08362 -73.76946  102.0\n",
      "49 2018-05-13 13:40:23  43.08362 -73.76949  110.0\n",
      "              Datetime        Lat       Long   Elev\n",
      "29 2018-05-13 13:40:03  43.083610 -73.769451  105.3\n",
      "30 2018-05-13 13:40:04  43.083614 -73.769454  105.4\n",
      "34 2018-05-13 13:40:08  43.083589 -73.769474  103.5\n",
      "35 2018-05-13 13:40:09  43.083617 -73.769466  102.8\n",
      "           PITS Image\n",
      "57   13_40_31-rot.jpg\n",
      "117  13_41_31-rot.jpg\n",
      "177  13_42_31-rot.jpg\n",
      "237  13_43_31-rot.jpg\n",
      "                                MSI Image  \\\n",
      "0    2018-05-13_133934-391900854-cam0.jpg   \n",
      "60   2018-05-13_134034-391900854-cam0.jpg   \n",
      "120  2018-05-13_134134-391900854-cam0.jpg   \n",
      "180  2018-05-13_134234-391900854-cam0.jpg   \n",
      "\n",
      "                             MSI IR Image  \n",
      "0    2018-05-13_133934-391900854-cam1.jpg  \n",
      "60   2018-05-13_134034-391900854-cam1.jpg  \n",
      "120  2018-05-13_134134-391900854-cam1.jpg  \n",
      "180  2018-05-13_134234-391900854-cam1.jpg  \n"
     ]
    }
   ],
   "source": [
    "print df_star.head(4)\n",
    "print df_tel.head(4)\n",
    "print df_gps.head(4)\n",
    "print df_pits.head(4)\n",
    "print df_msi.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-13 13:40:03 1526233203.0\n",
      "29 57 0\n"
     ]
    }
   ],
   "source": [
    "seconds = df_star.index.values[1:]\n",
    "counts = df_star.iloc[:,0].values[1:]\n",
    "deadt = df_star.iloc[:,7].values[1:]\n",
    "deadtc = df_star.iloc[:,8].values[1:]\n",
    "T_raw = df_star.iloc[:,1].values[1:]\n",
    "P_raw = df_star.iloc[:,3].values[1:]\n",
    "T = df_star.iloc[:,2].values[1:]\n",
    "P1 = df_star.iloc[:,4].values[1:]\n",
    "P2 = df_star.iloc[:,5].values[1:]\n",
    "alt = df_star.iloc[:,6].values[1:]\n",
    "\n",
    "# Turn this into elapsed time\n",
    "elapsed = seconds - seconds[0]\n",
    "\n",
    "# Telemetry info\n",
    "tel_seconds = df_gps.index.values[:]\n",
    "tel_dt = pd.to_datetime(np.array(df_gps.iloc[:,0].values[:]))\n",
    "tel_ts = [time.mktime(i.timetuple()) for i in tel_dt]\n",
    "tel_lat = np.array(df_gps.iloc[:,1].values[:], dtype='float')\n",
    "tel_long = np.array(df_gps.iloc[:,2].values[:], dtype='float')\n",
    "tel_alt = np.array(df_gps.iloc[:,3].values[:], dtype='float')\n",
    "\n",
    "pits_seconds = df_pits.index.values[:]\n",
    "pits_fn = np.array(df_pits.iloc[:,0].values[:], dtype='str')\n",
    "\n",
    "msi_seconds = df_msi.index.values[:]\n",
    "msi_fn = np.array(df_msi.iloc[:,0].values[:], dtype='str')\n",
    "msi_ir = np.array(df_msi.iloc[:,1].values[:], dtype='str')\n",
    "\n",
    "print tel_dt[0], tel_ts[0]\n",
    "print tel_seconds[0], pits_seconds[0], msi_seconds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR maximum altitude at:  12308.0\n",
      "Telemetry maximum altitude at:  9974\n",
      "Elapsed time offset:  2363.0 2418.0 2361.0\n"
     ]
    }
   ],
   "source": [
    "# Attempt to align the dataframes\n",
    "# Telemetry: altitude max at 9927\n",
    "# STAR: altitude max at 804614.504000\n",
    "# STAR: log started at 12:59:55pm\n",
    "\n",
    "star_max = elapsed[np.where(P2==np.min(P2))][0]\n",
    "tel_max = tel_seconds[np.where(tel_alt==np.max(tel_alt))][0]\n",
    "\n",
    "print \"STAR maximum altitude at: \", star_max\n",
    "print \"Telemetry maximum altitude at: \", tel_max\n",
    "\n",
    "# Align the two data sets\n",
    "tel_seconds2 = tel_seconds + (star_max - tel_max)  #+ 27\n",
    "pits_seconds2 = pits_seconds + (star_max - tel_max) + 27\n",
    "msi_seconds2 = msi_seconds + (star_max - tel_max) + 27\n",
    "\n",
    "print \"Elapsed time offset: \", tel_seconds2[0], pits_seconds2[0], msi_seconds2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create interpolation functions for the missing data\n",
    "alt_func = interp1d(tel_seconds2, tel_alt, fill_value='extrapolate')\n",
    "lat_func = interp1d(tel_seconds2, tel_lat, fill_value='extrapolate')\n",
    "long_func = interp1d(tel_seconds2, tel_long, fill_value='extrapolate')\n",
    "ts_func = interp1d(tel_seconds2, tel_ts, fill_value='extrapolate')\n",
    "\n",
    "seconds2 = np.array(elapsed, dtype='int')\n",
    "\n",
    "# Create expanded telemetry arrays\n",
    "lat2 = np.ones_like(seconds2) * np.nan\n",
    "long2 = np.ones_like(seconds2) * np.nan\n",
    "alt2 = np.ones_like(seconds2) * np.nan\n",
    "dt2 = np.empty(len(seconds2), dtype='datetime64[s]')\n",
    "fn2 = np.empty(len(seconds2), dtype='object')\n",
    "msi_fn1 = np.empty(len(seconds2), dtype='object')\n",
    "msi_fn2 = np.empty(len(seconds2), dtype='object')\n",
    "\n",
    "# Create a binary value to indicate interpolated data\n",
    "interp = np.zeros_like(seconds2)\n",
    "\n",
    "ts_last = 0\n",
    "ts_td = np.timedelta64(datetime.timedelta(seconds=1))\n",
    "\n",
    "for i in range(len(seconds2)):\n",
    "    cur_sec = seconds2[i]\n",
    "    try:\n",
    "        tel_loc = np.where(tel_seconds2 == cur_sec)[0][0]\n",
    "        #print tel_seconds2[tel_loc]\n",
    "        alt2[i] = tel_alt[tel_loc]\n",
    "        lat2[i] = tel_lat[tel_loc]\n",
    "        long2[i] = tel_long[tel_loc]\n",
    "        dt2[i] = np.datetime64(tel_dt[tel_loc])\n",
    "        interp[i] = int(0)\n",
    "    except:\n",
    "        if ((cur_sec >= tel_seconds2[0]) and (cur_sec <= tel_seconds2[-1])):\n",
    "            alt2[i] = alt_func(cur_sec)\n",
    "            lat2[i] = lat_func(cur_sec)\n",
    "            long2[i] = long_func(cur_sec)\n",
    "            interp[i] = int(1)\n",
    "        else:\n",
    "            alt2[i] = np.nan\n",
    "            lat2[i] = np.nan\n",
    "            long2[i] = np.nan\n",
    "            interp[i] = int(0)\n",
    "\n",
    "        try:\n",
    "            dt2[i] = np.datetime64(datetime.datetime.fromtimestamp(ts_func(cur_sec).tolist()))\n",
    "        except:\n",
    "            dt2[i] = ts_last + ts_td\n",
    "    try:\n",
    "        pits_loc = np.where(pits_seconds2 == cur_sec)[0][0]\n",
    "        fn2[i] = str(pits_fn[pits_loc])\n",
    "    except:\n",
    "        fn2[i] = ''\n",
    "\n",
    "    try:\n",
    "        msi_loc = np.where(msi_seconds2 == cur_sec)[0][0]\n",
    "        msi_fn1[i] = str(msi_fn[msi_loc])\n",
    "        msi_fn2[i] = str(msi_ir[msi_loc])\n",
    "    except:\n",
    "        msi_fn1[i] = ''\n",
    "        msi_fn2[i] = ''\n",
    "\n",
    "    ts_last = dt2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create new dataframes\n",
    "df_columns = ['Datetime', 'Elapsed', 'Counts', 'T [Raw]', 'T1 [C]', 'P [Raw]', 'P1 [mbar]', 'P2 [mbar]', 'Altitude [m]', 'Dead Time [s]', 'Dead Time Counts', 'GPS Lat', 'GPS Long', 'GPS Elev [m]', 'Interp?', 'PITS Image', 'MSI Image', 'MSI IR Image']\n",
    "z = zip(dt2, seconds, counts, T_raw, T, P_raw, P1, P2, alt, deadt, deadtc, lat2, long2, alt2, interp, fn2, msi_fn1, msi_fn2)\n",
    "df_final = pd.DataFrame(data=z, columns=df_columns, index=seconds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Datetime     Elapsed  Counts  T [Raw]     T1 [C]  P [Raw]  \\\n",
      "0 2018-05-13 13:00:40  792306.504      -1  8424604  29.627446  6760768   \n",
      "1 2018-05-13 13:00:41  792307.504      -1  8424642  29.628707  6760756   \n",
      "2 2018-05-13 13:00:42  792308.504      -1  8424664  29.629437  6760868   \n",
      "3 2018-05-13 13:00:43  792309.504      -1  8424698  29.630565  6760812   \n",
      "\n",
      "     P1 [mbar]    P2 [mbar]  Altitude [m]  Dead Time [s]  Dead Time Counts  \\\n",
      "0  1009.733632  1009.733632     97.467407            0.0                -1   \n",
      "1  1009.731755  1009.731755     97.483696            0.0                -1   \n",
      "2  1009.777593  1009.777593     97.091202            0.0                -1   \n",
      "3  1009.758057  1009.758057     97.258713            0.0                -1   \n",
      "\n",
      "   GPS Lat  GPS Long  GPS Elev [m]  Interp? PITS Image MSI Image MSI IR Image  \n",
      "0      NaN       NaN           NaN        0                                    \n",
      "1      NaN       NaN           NaN        0                                    \n",
      "2      NaN       NaN           NaN        0                                    \n",
      "3      NaN       NaN           NaN        0                                    \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-67e02f13eb2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoined_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print df_final.head(4)\n",
    "\n",
    "df_final.to_csv(joined_file, sep=',', encoding='ascii')\n",
    "\n",
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Free up some RAM\n",
    "del [[df, df2, df3, df4]]\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df2=pd.DataFrame()\n",
    "df3=pd.DataFrame()\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seconds = df5.index.values[1:]\n",
    "#counts = df5.iloc[:,0].values[1:]\n",
    "#T_raw = df5.iloc[:,1].values[1:]\n",
    "#T = df5.iloc[:,2].values[1:]\n",
    "#P_raw = df5.iloc[:,3].values[1:]\n",
    "#P1 = df5.iloc[:,4].values[1:]\n",
    "#P2 = df5.iloc[:,5].values[1:]\n",
    "#alt = df5.iloc[:,6].values[1:]\n",
    "#deadt = df5.iloc[:,7].values[1:]\n",
    "#deadtc = df5.iloc[:,8].values[1:]\n",
    "#lat = df5.iloc[:,9].values[1:]\n",
    "#lon = df5.iloc[:,10].values[1:]\n",
    "#elev = df5.iloc[:,11].values[1:]\n",
    "\n",
    "# Where are the counts >= 0?\n",
    "counts_min = loc_min_counts(df5['Dead Time Counts'], 0)\n",
    "\n",
    "# Time intervals\n",
    "dt = np.gradient(df5.index)\n",
    "\n",
    "# Average dead time\n",
    "avg_deadt = avg_deadtime(df5['Dead Time [s]'], df5['Dead Time Counts'])\n",
    "\n",
    "# Dead time correction\n",
    "counts_c = deadt_correction(dt, df5['Dead Time Counts'], avg_deadt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts and Pressure vs Time (Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mins = np.array(df5.index) / 60.0\n",
    "P2 = np.array(df5['P2 [mbar]'])\n",
    "\n",
    "counts_smoothed = savgol_filter(counts_c, 51, 1)\n",
    "counts_smoothed = running_mean(counts_smoothed, 300)\n",
    "#counts_smoothed = savgol_filter(counts_c, 101, 3)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(mins[counts_min], counts_smoothed[counts_min], 'r.')\n",
    "ax1.tick_params('y', colors='r')\n",
    "ax1.set_xlabel(\"Time [min]\")\n",
    "ax1.set_ylabel(\"Counts\")\n",
    "ax1.set_ylim([0, 20])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(mins[counts_min], P2[counts_min], 'b-', linewidth=3)\n",
    "ax2.tick_params('y', colors='b')\n",
    "ax2.set_ylabel(\"Pressure [mb]\")\n",
    "\n",
    "plt.xlim([mins[counts_min][0], mins[counts_min][-1]])\n",
    "\n",
    "#plt.savefig(\"%s\\counts_pressure_time.png\" % (data_dir), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts vs Pressure (Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "plt.semilogx(P2, counts_smoothed, 'r.')\n",
    "plt.xlabel(\"Pressure [mb]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "\n",
    "plt.xlim([np.min(P2), np.max(P2)])\n",
    "\n",
    "plt.savefig(\"%s\\counts_pressure.png\" % (data_dir), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elevation vs Time (Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "QFF = 1022  # https://weather.us/observations/new-york/pressure-qff/20180513-1500z.html\n",
    "alt_l = altitude_logarithmic(P2, T, QFF)\n",
    "alt_h = altitude_hypsometric(T, P2)\n",
    "\n",
    "print max(alt_l)\n",
    "\n",
    "plt.plot(seconds/60.0, alt/1000.0, 'r--', linewidth=3, label=\"Hypsometric approximation\")\n",
    "plt.plot(seconds/60.0, alt_l/1000.0, 'b--', linewidth=3, label=\"Logarithmic approximation\")\n",
    "plt.plot(seconds/60.0, alt2/1000.0, 'g-', linewidth=3, label=\"GPS (Measured and Interpolated)\")\n",
    "plt.xlabel(\"Time [min]\")\n",
    "plt.ylabel(\"Elevation [km]\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "\n",
    "plt.savefig(\"%s\\elevation_time.png\" % (data_dir), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts and Elevation vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "QFF = 1022  # https://weather.us/observations/new-york/pressure-qff/20180513-1500z.html\n",
    "alt_l = altitude_logarithmic(P2, T, QFF)\n",
    "\n",
    "counts_smoothed = savgol_filter(counts_c, 51, 1)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(seconds/60.0, counts_smoothed, 'r.')\n",
    "ax1.tick_params('y', colors='r')\n",
    "ax1.set_xlabel(\"Time [min]\")\n",
    "ax1.set_ylabel(\"Counts\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(seconds/60.0, alt_l/1000.0, 'b--', linewidth=3, label=\"Logarithmic approximation\")\n",
    "ax2.plot(seconds/60.0, alt2/1000.0, 'g-', linewidth=3, label=\"GPS (Measured and Interpolated)\")\n",
    "ax2.tick_params('y', colors='b')\n",
    "ax2.set_ylabel(\"Elevation [km]\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.savefig(\"%s\\counts_elevation_time.png\" % (data_dir), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velocity (Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "seconds_dt = np.gradient(seconds)\n",
    "dx = np.gradient(alt_l)\n",
    "\n",
    "v = np.array(dx/seconds_dt, dtype='float64')\n",
    "v_smooth = savgol_filter(v, 3, 1)\n",
    "plt.ylabel(\"Velocity [m/s]\")\n",
    "plt.xlabel(\"Time [min]\")\n",
    "\n",
    "minutes = np.array(seconds/60.0, dtype='float64')\n",
    "\n",
    "x = np.linspace(np.min(minutes), np.max(minutes), 1000)\n",
    "\n",
    "plt.plot(minutes, v_smooth, linewidth=3)\n",
    "plt.savefig(\"%s\\\\velocity_time.png\" % (data_dir), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velocity (Descent Only, Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "\n",
    "seconds_dt = np.gradient(seconds)\n",
    "dx = np.gradient(alt2)\n",
    "\n",
    "v = np.array(dx/seconds_dt, dtype='float64')\n",
    "v_smooth = savgol_filter(v, 3, 1)\n",
    "plt.ylabel(\"Velocity [m/s]\")\n",
    "plt.xlabel(\"Time [min]\")\n",
    "\n",
    "minutes = np.array((seconds-seconds[0])/60.0, dtype='float64')\n",
    "\n",
    "m = np.where(minutes >= 129.0)\n",
    "\n",
    "x = np.linspace(np.min(minutes[m]), np.max(minutes[m]), 1000)\n",
    "\n",
    "plt.plot(minutes[m], v_smooth[m], linewidth=3)\n",
    "#plt.plot(x, log_fit(x, a, b), 'r--')\n",
    "plt.savefig(\"%s\\\\velocity_descent.png\" % (data_dir), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Temperature vs Time (Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.ylabel(\"Internal temperature [C]\")\n",
    "plt.xlabel(\"Time [min]\")\n",
    "\n",
    "plt.plot((seconds-seconds[0])/60.0, T, linewidth=3)\n",
    "plt.savefig(\"%s\\\\temperature_time.png\" % (data_dir), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Temperature vs Estimated Elevation (Wes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Internal temperature [C]\")\n",
    "plt.ylabel(\"Estimated elevation [km]\")\n",
    "\n",
    "plt.plot(T, alt2/1000.0, linewidth=3)\n",
    "plt.savefig(\"%s\\\\elevation_temperature.png\" % (data_dir), dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time interval accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How reliable is our counting loop?\n",
    "seconds = df.index.values[1:]\n",
    "seconds_dt = np.gradient(seconds)\n",
    "\n",
    "mu, std = norm.fit(seconds_dt)\n",
    "\n",
    "N = len(seconds_dt)\n",
    "\n",
    "n, bins, patches = plt.hist(seconds_dt, bins=32, alpha=1.0, align='left', label=\"%d timer intervals\" % N)\n",
    "\n",
    "# Scale the normed distribution to fit our data\n",
    "dx = bins[1] - bins[0]\n",
    "scale = N*dx\n",
    "\n",
    "# Plot the fit\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "p = scale*norm.pdf(x, mu, std)\n",
    "#plt.plot(x, p, 'r--', linewidth=3, label=\"$\\mu$=%.4f s,  $\\sigma$=%.4f s\" % (mu, std))\n",
    "\n",
    "plt.title(\"Timer Duration\")\n",
    "plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time interval outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just look at the outliers\n",
    "seconds_dt_o = seconds_dt[np.where(seconds_dt != 1.0)]\n",
    "\n",
    "N_o = len(seconds_dt_o)\n",
    "pct_o = (1.0 * N_o) / (1.0 * N) * 100.0\n",
    "\n",
    "n, bins, patches = plt.hist(seconds_dt_o, bins=8, alpha=1.0, align='left', label=\"%d timer intervals, %0.1f percent\" % (N_o, pct_o))\n",
    "\n",
    "plt.title(\"Timer Outliers\")\n",
    "plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of counts/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = df.iloc[:,0].values[1:]\n",
    "seconds = df.index.values[1:]\n",
    "seconds_dt = np.gradient(seconds)\n",
    "\n",
    "cps = counts / seconds_dt\n",
    "cps = np.array(cps[np.where(cps >= 0)], dtype='float64')\n",
    "\n",
    "mincounts = 0\n",
    "\n",
    "cps = cps[cps >= mincounts]\n",
    "N = len(cps)\n",
    "\n",
    "halfn = True\n",
    "\n",
    "if (halfnorm):\n",
    "    mu, std = halfnorm.fit(cps)\n",
    "else:\n",
    "    mu, std = norm.fit(cps)\n",
    "\n",
    "n, bins, patches = plt.hist(cps, bins=8, alpha=1.0, align='mid', label=\"%d samples\" % N)\n",
    "\n",
    "# Scale the normed distribution to fit our data\n",
    "dx = bins[1] - bins[0]\n",
    "\n",
    "plt.xlim([min(cps), max(cps)])\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "\n",
    "if (halfnorm):\n",
    "    scale = N * 2/(np.sqrt(np.pi)) * dx\n",
    "    p = scale * halfnorm.pdf(x, mu, std)\n",
    "else:\n",
    "    scale = N*dx\n",
    "    p = scale*norm.pdf(x, mu, std)\n",
    "    \n",
    "plt.plot(x, p, 'r--', linewidth=3, label=\"$\\mu$=%.3f s$^{-1}$,  $\\sigma$=%.3f s$^{-1}$\" % (mu, std))\n",
    "\n",
    "plt.xlabel(\"Counts per Second\")\n",
    "plt.title(\"Launch\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dead time correction of histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seconds = df.index.values[1:]\n",
    "counts = df.iloc[:,0].values[1:]\n",
    "deadt = df.iloc[:,7].values[1:]\n",
    "deadtc = df.iloc[:,8].values[1:]\n",
    "T = df.iloc[:,2].values[1:]\n",
    "P1 = df.iloc[:,4].values[1:]\n",
    "P2 = df.iloc[:,5].values[1:]\n",
    "alt = df.iloc[:,6].values[1:]\n",
    "\n",
    "seconds, seconds_dt, counts, deadt, deadtc, T, P1, P2, alt = enforce_min_counts(seconds, counts, deadt, deadtc, T, P1, P2, alt, 0)\n",
    "\n",
    "avg_deadt = avg_deadtime(deadt, deadtc)\n",
    "\n",
    "counts_c = deadt_correction(seconds_dt, deadtc, avg_deadt)\n",
    "\n",
    "bins = np.linspace(np.min(counts_c), np.max(counts_c), 32)\n",
    "binwidth = bins[1]-bins[0]\n",
    "\n",
    "plt.hist([counts, counts_c], bins, alpha=1.0, align='left', \\\n",
    "         label=[\"%d samples representing %.1f counts\" % (len(counts), sum(counts)), \\\n",
    "                \"%d corrected samples representing %.1f counts\" % (len(counts_c), sum(counts_c))])\n",
    "\n",
    "plt.xlim([np.min(counts_c)-binwidth, np.max(counts_c)+binwidth])\n",
    "\n",
    "plt.xlabel(\"Counts per Second\")\n",
    "plt.title(\"Dead Time Correction, Launch\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average dead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (len(avg_deadt) > 1):\n",
    "    n, bins, patches = plt.hist(avg_deadt, bins=16, alpha=1.0, align='mid', \\\n",
    "         label=\"%d dead time samples\" % len(avg_deadt))\n",
    "    \n",
    "    mu, std = norm.fit(avg_deadt)\n",
    "    \n",
    "    plt.xlim([min(avg_deadt), max(avg_deadt)])\n",
    "    xmin, xmax = plt.xlim()\n",
    "    x = np.linspace(xmin, xmax, 1000)\n",
    "\n",
    "    dx = bins[1] - bins[0]\n",
    "    scale = N*dx\n",
    "    p = scale*norm.pdf(x, mu, std)\n",
    "    \n",
    "    plt.plot(x, p, 'r--', linewidth=3, label=\"$\\mu$=%.6f s$^{-1}$,  $\\sigma$=%.6f s$^{-1}$\" % (mu, std))\n",
    "\n",
    "    plt.xlabel(\"Dead Time Per Event (s)\")\n",
    "    plt.title(\"Average Dead Time Per Event\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pressure vs Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(T, P2, 'b-')\n",
    "ax1.set_xlabel('Measured Temperature (C)')\n",
    "\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('Measured Pressure (mbar)', color='b')\n",
    "ax1.tick_params('y', colors='b')\n",
    "plt.gca().get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(T, alt, 'r-')\n",
    "ax2.set_ylabel('Calculated Altitude (m)', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.gca().get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "\n",
    "plt.xlim(min(T), max(T))\n",
    "\n",
    "#fig.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(seconds-seconds[0], P2, T, c=seconds, cmap='viridis', linewidth=0.5)\n",
    "\n",
    "ax.xaxis.labelpad=30\n",
    "ax.yaxis.labelpad=30\n",
    "ax.zaxis.labelpad=30\n",
    "\n",
    "ax.set_zlabel(\"Temperature [C]\")\n",
    "ax.set_ylabel('Pressure [mb]')\n",
    "ax.set_xlabel('Elapsed Time [s]')\n",
    "\n",
    "plt.gca().get_yaxis().get_major_formatter().set_useOffset(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D plot of time, altitude, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seconds = df.index.values[1:]\n",
    "counts = df.iloc[:,0].values[1:]\n",
    "deadt = df.iloc[:,7].values[1:]\n",
    "deadtc = df.iloc[:,8].values[1:]\n",
    "T = df.iloc[:,2].values[1:]\n",
    "P1 = df.iloc[:,4].values[1:]\n",
    "P2 = df.iloc[:,5].values[1:]\n",
    "alt = df.iloc[:,6].values[1:]\n",
    "\n",
    "P1_min = np.min(P1)\n",
    "P2_min = np.min(P2)\n",
    "T_min = np.min(T)\n",
    "alt_max = np.max(alt)\n",
    "\n",
    "print P1_min, P2_min, T_min, alt_max\n",
    "\n",
    "seconds, seconds_dt, counts, deadt, deadtc, T, P1, P2, alt = enforce_min_counts(seconds, counts, deadt, deadtc, T, P1, P2, alt, 0)\n",
    "\n",
    "avg_deadt = avg_deadtime(deadt, deadtc)\n",
    "\n",
    "counts_c = deadt_correction(seconds_dt, deadtc, avg_deadt)\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(seconds-seconds[0], alt, counts_c, c=seconds, cmap='viridis', linewidth=0.5)\n",
    "\n",
    "ax.set_zlabel(\"Corrected Counts\")\n",
    "ax.set_ylabel('Calculated Altitude (m)')\n",
    "ax.set_xlabel('Elapsed Time (seconds)')\n",
    "plt.gca().get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "\n",
    "plt.title(\"Altitude and Counts vs Elapsed Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrected counts per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seconds = df.index.values[1:]\n",
    "counts = df.iloc[:,0].values[1:]\n",
    "deadt = df.iloc[:,7].values[1:]\n",
    "deadtc = df.iloc[:,8].values[1:]\n",
    "T = df.iloc[:,2].values[1:]\n",
    "P1 = df.iloc[:,4].values[1:]\n",
    "P2 = df.iloc[:,5].values[1:]\n",
    "alt = df.iloc[:,6].values[1:]\n",
    "\n",
    "seconds, seconds_dt, counts, deadt, deadtc, T, P1, P2, alt = enforce_min_counts(seconds, counts, deadt, deadtc, T, P1, P2, alt, 0)\n",
    "\n",
    "avg_deadt = avg_deadtime(deadt, deadtc)\n",
    "\n",
    "counts_c = deadt_correction(seconds_dt, deadtc, avg_deadt)\n",
    "\n",
    "cps = counts_c/seconds_dt\n",
    "cps_avg = np.sum(cps)/len(cps)\n",
    "\n",
    "x = range(int(np.max(seconds)-seconds[0])+1)\n",
    "y = np.ones_like(x)*cps_avg\n",
    "\n",
    "plt.plot(x, cps, 'b-', linewidth='0.5', alpha=0.75, label=\"Counts\")\n",
    "plt.title(\"Corrected Counts per Second\")\n",
    "plt.xlabel(\"Elapsed Time (s)\")\n",
    "plt.ylabel(\"Corrected Counts\")\n",
    "\n",
    "#plt.plot(x, y, 'r-', linewidth=\"3\", label=\"Average CPS: %.3f\" % cps_avg)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.xlim(np.min(x), np.max(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pressure and corrected counts versus elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seconds = df.index.values[1:]\n",
    "counts = df.iloc[:,0].values[1:]\n",
    "deadt = df.iloc[:,7].values[1:]\n",
    "deadtc = df.iloc[:,8].values[1:]\n",
    "T = df.iloc[:,2].values[1:]\n",
    "P1 = df.iloc[:,4].values[1:]\n",
    "P2 = df.iloc[:,5].values[1:]\n",
    "alt = df.iloc[:,6].values[1:]\n",
    "\n",
    "seconds, seconds_dt, counts, deadt, deadtc, T, P1, P2, alt = enforce_min_counts(seconds, counts, deadt, deadtc, T, P1, P2, alt, 0)\n",
    "\n",
    "avg_deadt = avg_deadtime(deadt, deadtc)\n",
    "\n",
    "counts_c = deadt_correction(seconds_dt, deadtc, avg_deadt)\n",
    "\n",
    "# Let's smooth this a bit\n",
    "counts_smoothed = counts_c\n",
    "for i in range(0, 250):\n",
    "    counts_smoothed = savgol_filter(counts_smoothed, 3, 1)\n",
    "\n",
    "elapsed = seconds-seconds[0]\n",
    "                                \n",
    "#plt.plot(seconds, P2)\n",
    "#plt.title(\"Pressure vs Elapsed Time\")\n",
    "#plt.xlabel(\"Elapsed Time (s)\")\n",
    "#plt.ylabel(\"Pressure (mbar)\")\n",
    "#plt.savefig(\"%s\\pressure_time.png\" % (data_dir), bbox_inches='tight')\n",
    "#plt.show()\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(elapsed, P2, 'b-')\n",
    "ax1.set_xlabel('Elapsed Time (s)')\n",
    "\n",
    "# Make the y-axis label, ticks and tick labels match the line color.\n",
    "ax1.set_ylabel('Pressure (mbar)', color='b')\n",
    "ax1.tick_params('y', colors='b')\n",
    "ax1.set_ylim([np.min(P2), np.max(P2)])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(elapsed, counts_smoothed, 'r-')\n",
    "ax2.set_ylabel('Counts', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "ax2.set_ylim([np.min(counts_c), 25])\n",
    "\n",
    "plt.title(\"Pressure and Counts vs Elapsed Time\")\n",
    "plt.xlim(np.min(elapsed), np.max(elapsed))\n",
    "plt.savefig(\"%s\\pressure_counts_time.png\" % (data_dir), bbox_inches='tight')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
